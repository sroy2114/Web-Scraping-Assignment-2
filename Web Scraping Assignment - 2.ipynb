{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033a8ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef0748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2045a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb787f",
   "metadata": {},
   "source": [
    "# Question 1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d56263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Naukri page on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9615a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b46db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a93d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6c576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering blank titles\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ae9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# scraping Job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# scraping company name from the given page    \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# scraping Experience from the given page    \n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d723ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5c926b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...</td>\n",
       "      <td>Coresight Research, Inc.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                        Data Analyst - CRM Platform   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "6  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "7                Payroll Transformation Data Analyst   \n",
       "8                Payroll Transformation Data Analyst   \n",
       "9            Master Data Management Business Analyst   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                       Bangalore/Bengaluru, Chennai   \n",
       "1  Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "6  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "               Company_name Exp_required  \n",
       "0                Latentview      3-6 Yrs  \n",
       "1  Coresight Research, Inc.      4-8 Yrs  \n",
       "2                    Varite      2-5 Yrs  \n",
       "3         Artech infosystem      1-6 Yrs  \n",
       "4                       Jar      0-4 Yrs  \n",
       "5                 Cognizant      3-8 Yrs  \n",
       "6                 Cognizant      6-9 Yrs  \n",
       "7         Arrow Electronics     5-10 Yrs  \n",
       "8         Arrow Electronics      3-7 Yrs  \n",
       "9                 Accenture      6-8 Yrs  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d99224",
   "metadata": {},
   "source": [
    "# Question 2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e05e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Naukri page on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa84651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34348d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50315def",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8035c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering blank titles\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3adfb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# scraping Job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# scraping company name from the given page    \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# scraping Experience from the given page    \n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "700485bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e86e8c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8                   Data Scientist - Computer Vision   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        Job_location             Company_name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis   \n",
       "3                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech   \n",
       "4  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates   \n",
       "5  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra   \n",
       "6    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group   \n",
       "7                                Bangalore/Bengaluru                      IBM   \n",
       "8                                Bangalore/Bengaluru                  Walmart   \n",
       "9                 Bangalore/Bengaluru, Pune, Chennai                    Wipro   \n",
       "\n",
       "  Exp_required  \n",
       "0      2-4 Yrs  \n",
       "1      4-7 Yrs  \n",
       "2     9-14 Yrs  \n",
       "3      5-9 Yrs  \n",
       "4      5-8 Yrs  \n",
       "5    10-14 Yrs  \n",
       "6     5-10 Yrs  \n",
       "7      4-8 Yrs  \n",
       "8      3-7 Yrs  \n",
       "9     8-13 Yrs  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acbfd07",
   "metadata": {},
   "source": [
    "# Question 3: In this question you have to scrape data using the filters available on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8d42137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a12fd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Naukri page on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "014b81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation required in the question\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c9ee796",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6555afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying location filter checkbox\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87980a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying salary filter checkbox\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95bf353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering blank titles\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdd5c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# scraping Job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# scraping company name from the given page    \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# scraping Experience from the given page    \n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22022180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4cf92cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Activation Specialist - Adobe Target</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Mumbai - Immediate Joiner Req...</td>\n",
       "      <td>Delhi / NCR, Mumbai, New Delhi</td>\n",
       "      <td>HueCanvas Consulting</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                  Data Scientist - Engine Algorithm   \n",
       "1                                     Data Scientist   \n",
       "2                    DigitalBCG GAMMA Data Scientist   \n",
       "3          Data Activation Specialist - Adobe Target   \n",
       "4                                     Data Scientist   \n",
       "5                                Lead Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                Data Scientist / Chat-bot Developer   \n",
       "8  Data Scientist - Mumbai - Immediate Joiner Req...   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job_location             Company_name  \\\n",
       "0  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...             Primo Hiring   \n",
       "1                 Noida, Nagpur, Bangalore/Bengaluru              GlobalLogic   \n",
       "2                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "3  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...           Okda Solutions   \n",
       "4                                   Gurgaon/Gurugram               IHS Markit   \n",
       "5         Noida(Sector-59 Noida)\\n(WFH during Covid)  R Systems International   \n",
       "6                                   Gurgaon/Gurugram                    Optum   \n",
       "7  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...             Big Seo Buzz   \n",
       "8                     Delhi / NCR, Mumbai, New Delhi     HueCanvas Consulting   \n",
       "9                                              Noida             NGI Ventures   \n",
       "\n",
       "  Exp_required  \n",
       "0      1-3 Yrs  \n",
       "1     8-10 Yrs  \n",
       "2      2-5 Yrs  \n",
       "3     7-10 Yrs  \n",
       "4      3-6 Yrs  \n",
       "5     7-10 Yrs  \n",
       "6      2-7 Yrs  \n",
       "7      3-7 Yrs  \n",
       "8      2-7 Yrs  \n",
       "9      0-5 Yrs  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc7053",
   "metadata": {},
   "source": [
    "# Question 4: Scrape data of first 100 sunglasses listings on flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fac8c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Flipkart page on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "281800a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering sunglasses required in the question\n",
    "\n",
    "Eyewear=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "Eyewear.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c47e0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed0bf6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 119\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "brand_sg =[]\n",
    "product_description_sg = []\n",
    "price_sg = []\n",
    "discount_sg = []\n",
    "\n",
    "\n",
    "# Scarping 100 sunglasses\n",
    "for page in range(0,3):\n",
    "    # Scraping the brand names of the sunglasses\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for brand in brand_tags:\n",
    "        brand_sg.append(brand.text)\n",
    "        \n",
    "    # Scraping the product description of sunglasses\n",
    "    product_description_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for pr_des in product_description_tags:\n",
    "        product_description_sg.append(pr_des.text)\n",
    "    \n",
    "    # Scraping the 'Price' of the sunglasses\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for price in price_tags:\n",
    "        price_sg.append(price.text)\n",
    "        \n",
    "    # Scraping the \"Discount\" given for the sunglasses\n",
    "    discount_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for discount in discount_tags:\n",
    "        discount_sg.append(discount.text)\n",
    "        \n",
    "    # Moving the next page of sunglasses\n",
    "    next_page = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]//span')\n",
    "    next_page.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "print(len(brand_sg),len(product_description_sg),len(price_sg),len(discount_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae6e6fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 100 sunglasses -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹198</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored Sports Sunglasses (62)</td>\n",
       "      <td>₹345</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹246</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (57)</td>\n",
       "      <td>₹157</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (55)</td>\n",
       "      <td>₹561</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0      ROZZETTA CRAFT              UV Protection Aviator Sunglasses (55)   \n",
       "1      ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3               NuVew              UV Protection Aviator Sunglasses (57)   \n",
       "4   SHAAH COLLECTIONS   UV Protection, Mirrored Wayfarer Sunglasses (54)   \n",
       "..                ...                                                ...   \n",
       "95              NuVew     UV Protection, Mirrored Sports Sunglasses (62)   \n",
       "96             PIRASO          UV Protection Rectangular Sunglasses (52)   \n",
       "97  SHAAH COLLECTIONS              UV Protection Aviator Sunglasses (54)   \n",
       "98              NuVew   UV Protection, Mirrored Wayfarer Sunglasses (57)   \n",
       "99          ROYAL SON          UV Protection Rectangular Sunglasses (55)   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹649  74% off  \n",
       "1   ₹449  77% off  \n",
       "2   ₹799  20% off  \n",
       "3   ₹198  73% off  \n",
       "4   ₹179  86% off  \n",
       "..   ...      ...  \n",
       "95  ₹345  84% off  \n",
       "96  ₹246  82% off  \n",
       "97  ₹179  82% off  \n",
       "98  ₹157  71% off  \n",
       "99  ₹561  89% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 sunglasses\n",
    "sunglasses_df = pd.DataFrame({'Brand':brand_sg[0:100], 'Product Description':product_description_sg[0:100],\"Price\":price_sg[0:100], \"Discount\":discount_sg[0:100]})\n",
    "print('-'*25,\"First 100 sunglasses\",'-'*25)\n",
    "sunglasses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f216d",
   "metadata": {},
   "source": [
    "# Question5: Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c7f4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Flipkart page on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "926fbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering iphone11 in the search field\n",
    "\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"iphone11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e76aaded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for iphone11\n",
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "11b30f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the first iphone11, scraping ratings, review summary and full review\n",
    "iphone11 = driver.find_element(By.CLASS_NAME,\"_4rR01T\")\n",
    "iphone11.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d1c4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to scrape required data\n",
    "rating_ip11 =[]\n",
    "review_summary_ip11 =[]\n",
    "full_review_ip11 =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "234f8426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 120 120\n"
     ]
    }
   ],
   "source": [
    "# the page having only 10 reviews, need to click on '+' to get 100 reviews\n",
    "for ip_11 in range(0,15):\n",
    "    # Scraping the rating of \"iphone 11\"\n",
    "    rating = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for rt in rating:\n",
    "        rating_ip11.append(rt.text)\n",
    "        \n",
    "    # Scraping the review summary for \"iphone 11\"\n",
    "    review_summary = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "    for rs in review_summary:\n",
    "        review_summary_ip11.append(rs.text)\n",
    "        \n",
    "    # Scraping the full review for \"iphone 11\"\n",
    "    full_review = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]//div//div')\n",
    "    for fr in full_review:\n",
    "        full_review_ip11.append(fr.text)\n",
    "        \n",
    "    # clicking on the '+' button to get other reviews\n",
    "#     all_reviews.click()\n",
    "#     time.sleep(2)\n",
    "\n",
    "\n",
    "print(len(rating_ip11),len(review_summary_ip11), len(full_review_ip11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9c6a8187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Very bad mic within 2 days my phone mic is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Fantastic and prompt delivery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Very bad mic within 2 days my phone mic is not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating          Review Summary  \\\n",
       "0       5        Perfect product!   \n",
       "1       5                Terrific   \n",
       "2       5          Simply awesome   \n",
       "3       4  Don't waste your money   \n",
       "4       5    Good quality product   \n",
       "..    ...                     ...   \n",
       "95      5   Mind-blowing purchase   \n",
       "96      5        Perfect product!   \n",
       "97      5                Terrific   \n",
       "98      5          Simply awesome   \n",
       "99      5  Don't waste your money   \n",
       "\n",
       "                                          Full review  \n",
       "0   After using 3 years mobile review. Excellent &...  \n",
       "1   I am using the phone for last 5 years and foun...  \n",
       "2   Really satisfied with the Product I received.....  \n",
       "3   Very bad mic within 2 days my phone mic is not...  \n",
       "4   impressively Nice......\\nOne of the greatest i...  \n",
       "..                                                ...  \n",
       "95                     Fantastic and prompt delivery.  \n",
       "96  After using 3 years mobile review. Excellent &...  \n",
       "97  I am using the phone for last 5 years and foun...  \n",
       "98  Really satisfied with the Product I received.....  \n",
       "99  Very bad mic within 2 days my phone mic is not...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 'iphone 11' reviews\n",
    "ip11_df = pd.DataFrame({'Rating':rating_ip11[0:100],'Review Summary':review_summary_ip11[0:100], 'Full review': full_review_ip11[0:100]})\n",
    "ip11_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc11cf",
   "metadata": {},
   "source": [
    "# Question6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821b492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bad48815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Flipkart page on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ec2fd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Sneakers” in the search field\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "84d76762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.CLASS_NAME, \"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9b1d721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 113 120 120\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "brand_sks =[]\n",
    "product_description_sks = []\n",
    "price_sks = []\n",
    "discount_sks = []\n",
    "\n",
    "\n",
    "# Scarping 100 'Sneakers'\n",
    "for page in range(0,3):\n",
    "    # Scraping the brand names of the 'Sneakers'\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for brand in brand_tags[0:100]:\n",
    "        brand_sks.append(brand.text)\n",
    "        \n",
    "    # Scraping the product description of 'Sneakers'\n",
    "    product_description_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for pr_des in product_description_tags[0:100]:\n",
    "        product_description_sks.append(pr_des.text)\n",
    "    \n",
    "    # Scraping the 'Price' of the 'Sneakers'\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for price in price_tags[0:100]:\n",
    "        price_sks.append(price.text)\n",
    "        \n",
    "    # Scraping the \"Discount\" given for the 'Sneakers'\n",
    "    discount_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for discount in discount_tags[0:100]:\n",
    "        discount_sks.append(discount.text)\n",
    "        \n",
    "    # Moving the next page of 'Sneakers'\n",
    "    next_page = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]//span')\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "print(len(brand_sks),len(product_description_sks),len(price_sks),len(discount_sks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d1f88b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹590</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹413</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>₹470</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹259</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>JUDDee</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹431</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Exclusive Sneaker Shoes Sneakers For Men</td>\n",
       "      <td>₹389</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹636</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Pa Poosh</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                Product Description   Price  \\\n",
       "0    RapidBox                                   Sneakers For Men    ₹590   \n",
       "1   Deals4you                                 Sneakers For Women    ₹413   \n",
       "2      BRUTON               Modern Trendy Shoes Sneakers For Men    ₹470   \n",
       "3    RED TAPE                                   Sneakers For Men  ₹1,499   \n",
       "4      BRUTON  Lightweight Pack Of 1 Trendy Sneakers Sneakers...    ₹259   \n",
       "..        ...                                                ...     ...   \n",
       "95     JUDDee  Original Luxury Branded Fashionable Men's Casu...    ₹599   \n",
       "96         TR                                   Sneakers For Men    ₹431   \n",
       "97  Deals4you           Exclusive Sneaker Shoes Sneakers For Men    ₹389   \n",
       "98     BRUTON                                   Sneakers For Men    ₹636   \n",
       "99   Pa Poosh                          Sneakers Sneakers For Men    ₹599   \n",
       "\n",
       "   Discount  \n",
       "0   40% off  \n",
       "1   72% off  \n",
       "2   63% off  \n",
       "3   70% off  \n",
       "4   56% off  \n",
       "..      ...  \n",
       "95  40% off  \n",
       "96  71% off  \n",
       "97  61% off  \n",
       "98  74% off  \n",
       "99  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 'Sneakers'\n",
    "sneakers_df = pd.DataFrame({'Brand':brand_sks[0:100], 'Product Description':product_description_sks[0:100],\"Price\":price_sks[0:100], \"Discount\":discount_sks[0:100]})\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92845ff",
   "metadata": {},
   "source": [
    "# Question 7: Go to the link - https://www.myntra.com/shoes Set second Price filter and Color filter to “Black”, as shown in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "06ff40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Myntra page on automated chrome browser \n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e8b15cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying second price filter checkbox\n",
    "Second_Price=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "52b65f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying black_color filter checkbox\n",
    "color=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8acf59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "brand_shoe =[]\n",
    "product_description_shoe = []\n",
    "price_shoe = []\n",
    "\n",
    "\n",
    "# Scarping 100 'Sneakers'\n",
    "for page in range(0,4):\n",
    "    # Scraping the brand names of the 'Sneakers'\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"product-brand\"]')\n",
    "    for brand in brand_tags[0:100]:\n",
    "        brand_shoe.append(brand.text)\n",
    "        \n",
    "    # Scraping the product description of 'Sneakers'\n",
    "    product_description_tags = driver.find_elements(By.XPATH, '//div[@class=\"product-product\"]')\n",
    "    for pr_des in product_description_tags[0:100]:\n",
    "        product_description_shoe.append(pr_des.text)\n",
    "    \n",
    "    # Scraping the 'Price' of the 'Sneakers'\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"product-discountedPrice\"]')\n",
    "    for price in price_tags[0:100]:\n",
    "        price_shoe.append(price.text)\n",
    "        \n",
    "        \n",
    "    # Moving the next page of 'Sneakers'\n",
    "    next_page = driver.find_element(By.XPATH, '//li[@class=\"pagination-next\"]//span')\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "37b02d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "#checking length\n",
    "print(len(brand_shoe),len(product_description_shoe),len(price_shoe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e1edd28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand, Product Description, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 'Sneakers'\n",
    "sneakers_df = pd.DataFrame({'Brand':brand_shoe[0:100], 'Product Description':product_description_shoe[0:100],\"Price\":price_shoe[0:100]})\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8112fdd0",
   "metadata": {},
   "source": [
    "# Question 8: Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0db5d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the amazon page on automated chrome browser \n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1f7a8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Laptop” in the search field \n",
    "product = driver.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "product.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7d244f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.XPATH, '//input[@id=\"nav-search-submit-button\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "93441625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the laptops based on “Intel Core i7”\n",
    "filter_laptop = driver.find_element(By.XPATH,'//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\" and @aria-label=\"Intel Core i7\" ]//span')\n",
    "filter_laptop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "00f72155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "title_laptop = []\n",
    "ratings_laptop = []\n",
    "price_laptop = []\n",
    "\n",
    "\n",
    "# Scraping the title of laptops\n",
    "title = driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for t in title[0:10]:\n",
    "    title_laptop.append(t.text)\n",
    "\n",
    "    \n",
    "# Scraping the ratings of laptop\n",
    "ratings = driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "for r in ratings[0:10]:\n",
    "    ratings_laptop.append(r.get_attribute('text'))\n",
    "    \n",
    "\n",
    "# Scraping the price of laptop\n",
    "price = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for p in price[0:10]:\n",
    "    price_laptop.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a2bff783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    " print(len(title_laptop),len(ratings_laptop),len(price_laptop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eb93bf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>1,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>93,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Nitro 5 Core i7 11th Gen 15.6\" (39.62cms)...</td>\n",
       "      <td>2.9 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.8 out of 5 stars   \n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...  4.2 out of 5 stars   \n",
       "2  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...  4.3 out of 5 stars   \n",
       "3  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  4.5 out of 5 stars   \n",
       "4  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.8 out of 5 stars   \n",
       "5  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.3 out of 5 stars   \n",
       "6  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.2 out of 5 stars   \n",
       "7  HP Pavilion x360 11th Gen Intel Core i7 14 inc...  4.2 out of 5 stars   \n",
       "8  Acer Nitro 5 Core i7 11th Gen 15.6\" (39.62cms)...  2.9 out of 5 stars   \n",
       "9  Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...  3.6 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    67,990  \n",
       "1  1,00,000  \n",
       "2    93,290  \n",
       "3    79,990  \n",
       "4    67,990  \n",
       "5    77,990  \n",
       "6    86,990  \n",
       "7    80,990  \n",
       "8    89,990  \n",
       "9  1,09,990  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 10 'Laptops'\n",
    "sneakers_df = pd.DataFrame({'Title':title_laptop[0:10], 'Ratings':ratings_laptop[0:10],\"Price\":price_laptop[0:10]})\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95cd975",
   "metadata": {},
   "source": [
    "# Q9: - Skip as per instruction from Gulshna Chaudhary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5840d",
   "metadata": {},
   "source": [
    "# 10: Write a python program to scrape the salary data for Data Scientist designation.You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. The above task will be, done as shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7d258626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the ambition_box page on automated chrome browser \n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2df3f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on the salaries dropdown option\n",
    "color=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[3]/i\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8b2a57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on the browse_salaries option\n",
    "color=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/p\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "85092cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of “Search Job Profile” enters “Data Scientist”\n",
    "data_sc = driver.find_element(By.XPATH, '//input[@type=\"searchbox\"]')\n",
    "data_sc.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cc8f251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then click on “Data Scientist”\n",
    "ds = driver.find_element(By.XPATH, '//html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1d7ce45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then click on “Data Scientist”\n",
    "ds = driver.find_element(By.XPATH, '/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9bd63645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Creating the empty list for the required data to be scraped\n",
    "company_n = []\n",
    "total_salary_record=[]\n",
    "avg_salary = []\n",
    "min_salary=[]\n",
    "max_salary=[]\n",
    "exp_reqd =[]\n",
    "\n",
    "# Getting the names of the company\n",
    "cn = driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for n in cn[0:10]:\n",
    "    cd = n.text.split()[:-10]\n",
    "    name = ''\n",
    "    company_n.append(name.join(cd))\n",
    "\n",
    "# Getting the total salary record of the company\n",
    "cn = driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for n in cn[0:10]:\n",
    "    s = n.text.split()[-2:]\n",
    "    total_salary_record.append(s[0])\n",
    "\n",
    "# Getting the average salary of the company\n",
    "avg_s = driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for av in avg_s:\n",
    "    avg_salary.append(av.text)\n",
    "\n",
    "# Getting the Maximum and Minimum salary of the company\n",
    "max_min_s = driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for mm in range(len(max_min_s)):\n",
    "    if mm % 2 == 0:\n",
    "        min_salary.append(max_min_s[mm].text)\n",
    "    elif mm % 2 == 1:\n",
    "        max_salary.append(max_min_s[mm].text)\n",
    "        \n",
    "# Getting the experience required\n",
    "exp = driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for er in exp[0:10]:\n",
    "    ex = er.text.split()[:-4]\n",
    "    exp_reqd.append(ex[0]+' '+ex[1])\n",
    "\n",
    "print(len(company_n),len(total_salary_record),len(avg_salary),len(max_salary),len(min_salary),len(exp_reqd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "eb66b37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total salary record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Experince Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>24</td>\n",
       "      <td>₹ 32.2L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbInbev</td>\n",
       "      <td>59</td>\n",
       "      <td>₹ 19.8L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>49</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>35</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>1-2 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FractalAnalytics</td>\n",
       "      <td>118</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SigmoidAnalytics</td>\n",
       "      <td>10</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>1 yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TigerAnalytics</td>\n",
       "      <td>70</td>\n",
       "      <td>₹ 14.6L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LegatoHealthTechnologies</td>\n",
       "      <td>11</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>10</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>14</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>3 yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name Total salary record Average Salary Maximum Salary  \\\n",
       "0                   Walmart                  24        ₹ 32.2L        ₹ 45.0L   \n",
       "1                   AbInbev                  59        ₹ 19.8L        ₹ 26.0L   \n",
       "2                     Optum                  49        ₹ 16.4L        ₹ 22.6L   \n",
       "3                        ZS                  35        ₹ 15.9L        ₹ 22.0L   \n",
       "4          FractalAnalytics                 118        ₹ 15.5L        ₹ 23.0L   \n",
       "5          SigmoidAnalytics                  10        ₹ 14.7L        ₹ 19.7L   \n",
       "6            TigerAnalytics                  70        ₹ 14.6L        ₹ 20.0L   \n",
       "7  LegatoHealthTechnologies                  11        ₹ 14.5L        ₹ 20.0L   \n",
       "8                      HSBC                  10        ₹ 14.0L        ₹ 18.0L   \n",
       "9                  Tredence                  14        ₹ 13.9L        ₹ 17.5L   \n",
       "\n",
       "  Minimum Salary Experince Required  \n",
       "0        ₹ 25.0L            3-4 yrs  \n",
       "1        ₹ 15.0L            2-4 yrs  \n",
       "2        ₹ 11.0L            2-4 yrs  \n",
       "3        ₹ 11.0L            1-2 yrs  \n",
       "4         ₹ 9.0L            2-4 yrs  \n",
       "5        ₹ 12.7L               1 yr  \n",
       "6         ₹ 9.0L            2-4 yrs  \n",
       "7        ₹ 11.0L              4 yrs  \n",
       "8        ₹ 12.0L              4 yrs  \n",
       "9         ₹ 8.8L              3 yrs  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for first 10 the salary data for Data Scientist designation \n",
    "salary_df = pd.DataFrame({'Company Name':company_n, 'Total salary record':total_salary_record,'Average Salary':avg_salary,\n",
    "                         'Maximum Salary':max_salary,'Minimum Salary':min_salary,'Experince Required':exp_reqd})\n",
    "salary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3ad48",
   "metadata": {},
   "source": [
    "# Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
